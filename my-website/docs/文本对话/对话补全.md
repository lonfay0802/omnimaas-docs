# 对话补全

## 概述

OmniMaaS 提供统一的对话补全接口，完全兼容 OpenAI Chat Completions API 协议。您只需切换 API 地址和密钥，即可无缝接入，支持 OpenAI、Anthropic、Google 等多家厂商的模型。

**核心特性：**
- ✅ 完全兼容 OpenAI API 协议
- ✅ 支持流式输出（SSE）
- ✅ 支持函数调用（Function Calling）
- ✅ 支持多模态输入（文本、图片、音频）
- ✅ 统一的错误处理和计费

## 快速开始

### 接口地址
```
POST https://api.omnimaas.com/v1/chat/completions
```

### 请求头

| 参数名 | 类型 | 必填 | 说明 |
|--------|------|------|------|
| Authorization | string | 是 | Bearer Token，格式：`Bearer YOUR_API_KEY` |
| Content-Type | string | 是 | 固定为 `application/json` |

### 基础请求示例

```bash
curl https://api.omnimaas.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "gpt-4",
    "messages": [
      {
        "role": "user",
        "content": "你好，请介绍一下你自己"
      }
    ]
  }'
```

## 常用参数

### 请求参数

| 参数名 | 类型 | 必填 | 默认值 | 说明 |
|--------|------|------|--------|------|
| model | string | 是 | - | 模型ID，如 `gpt-4`、`claude-3-5-sonnet-20241022`、`gemini-2.0-flash-exp` |
| messages | array | 是 | - | 对话消息列表，按时间顺序排列 |
| messages[].role | string | 是 | - | 消息角色：`system`、`user`、`assistant`、`tool` |
| messages[].content | string/array | 是 | - | 消息内容，支持文本或多模态内容 |
| stream | boolean | 否 | false | 是否启用流式输出 |
| temperature | number | 否 | 1.0 | 采样温度，范围 0-2。值越高输出越随机，越低越确定 |
| max_tokens | integer | 否 | - | 最大生成token数 |
| top_p | number | 否 | 1.0 | 核采样参数，范围 0-1 |

### 流式输出示例

```bash
curl https://api.omnimaas.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "gpt-4",
    "messages": [{"role": "user", "content": "讲个笑话"}],
    "stream": true
  }'
```

## 多模态输入

### 图片输入示例

```bash
curl https://api.omnimaas.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "这张图片里有什么？"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "https://example.com/image.jpg"
            }
          }
        ]
      }
    ]
  }'
```

## 响应格式

### 响应参数

| 参数名 | 类型 | 说明 |
|--------|------|------|
| id | string | 本次对话补全的唯一标识符 |
| object | string | 对象类型，固定为 `chat.completion` |
| created | integer | 创建时间的 Unix 时间戳（秒） |
| model | string | 实际使用的模型 ID |
| choices | array | 对话补全结果列表 |
| choices[].index | integer | 当前结果在数组中的索引 |
| choices[].message | object | 模型生成的消息 |
| choices[].message.role | string | 消息角色，通常为 `assistant` |
| choices[].message.content | string | 消息内容 |
| choices[].finish_reason | string | 停止原因：`stop`（自然结束）、`length`（达到最大长度）、`content_filter`（内容过滤）、`tool_calls`（工具调用） |
| usage | object | Token 使用统计 |
| usage.prompt_tokens | integer | 输入使用的 token 数 |
| usage.completion_tokens | integer | 输出使用的 token 数 |
| usage.total_tokens | integer | 总 token 数 |

### 非流式响应示例

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1677652288,
  "model": "gpt-4",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "你好！我是一个AI助手，很高兴为你服务。"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 15,
    "total_tokens": 35
  }
}
```

### 流式响应示例

流式响应通过 Server-Sent Events (SSE) 返回，每个数据块格式如下：

```
data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4","choices":[{"index":0,"delta":{"content":"你好"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4","choices":[{"index":0,"delta":{"content":"！"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]
```

## 代码示例

### Python 示例

#### 非流式调用

```python
import requests

url = 'https://api.omnimaas.com/v1/chat/completions'

headers = {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_API_KEY'
}

data = {
    "model": "gpt-4",
    "messages": [
        {"role": "user", "content": "你好，请介绍一下你自己"}
    ],
    "temperature": 0.7
}

try:
    response = requests.post(url, headers=headers, json=data)
    response.raise_for_status()

    result = response.json()
    print(f"回复: {result['choices'][0]['message']['content']}")
    print(f"Token使用: {result['usage']}")

except requests.exceptions.RequestException as e:
    print(f"请求失败: {e}")
```

#### 流式调用

```python
import requests

url = 'https://api.omnimaas.com/v1/chat/completions'

headers = {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_API_KEY'
}

data = {
    "model": "gpt-4",
    "messages": [
        {"role": "user", "content": "讲个笑话"}
    ],
    "stream": True
}

try:
    response = requests.post(url, headers=headers, json=data, stream=True)
    response.raise_for_status()

    for line in response.iter_lines():
        if line:
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]
                if data_str != '[DONE]':
                    import json
                    chunk = json.loads(data_str)
                    if chunk['choices'][0]['delta'].get('content'):
                        print(chunk['choices'][0]['delta']['content'], end='', flush=True)

except requests.exceptions.RequestException as e:
    print(f"请求失败: {e}")
```

### Go 示例

#### 非流式调用

```go
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
)

type Message struct {
    Role    string `json:"role"`
    Content string `json:"content"`
}

type ChatRequest struct {
    Model       string    `json:"model"`
    Messages    []Message `json:"messages"`
    Temperature float64   `json:"temperature,omitempty"`
}

type ChatResponse struct {
    ID      string `json:"id"`
    Choices []struct {
        Message struct {
            Content string `json:"content"`
        } `json:"message"`
    } `json:"choices"`
    Usage struct {
        TotalTokens int `json:"total_tokens"`
    } `json:"usage"`
}

func main() {
    url := "https://api.omnimaas.com/v1/chat/completions"

    reqBody := ChatRequest{
        Model: "gpt-4",
        Messages: []Message{
            {Role: "user", Content: "你好，请介绍一下你自己"},
        },
        Temperature: 0.7,
    }

    jsonData, _ := json.Marshal(reqBody)
    req, _ := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
    req.Header.Set("Content-Type", "application/json")
    req.Header.Set("Authorization", "Bearer YOUR_API_KEY")

    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        fmt.Printf("请求失败: %v\n", err)
        return
    }
    defer resp.Body.Close()

    body, _ := io.ReadAll(resp.Body)
    var result ChatResponse
    json.Unmarshal(body, &result)

    fmt.Printf("回复: %s\n", result.Choices[0].Message.Content)
    fmt.Printf("Token使用: %d\n", result.Usage.TotalTokens)
}
```

### Node.js 示例

#### 非流式调用

```javascript
const axios = require('axios');

const url = 'https://api.omnimaas.com/v1/chat/completions';

const headers = {
    'Content-Type': 'application/json',
    'Authorization': 'Bearer YOUR_API_KEY'
};

const data = {
    model: 'gpt-4',
    messages: [
        { role: 'user', content: '你好，请介绍一下你自己' }
    ],
    temperature: 0.7
};

axios.post(url, data, { headers })
    .then(response => {
        console.log('回复:', response.data.choices[0].message.content);
        console.log('Token使用:', response.data.usage);
    })
    .catch(error => {
        console.error('请求失败:', error.message);
    });
```

#### 流式调用

```javascript
const https = require('https');

const options = {
    hostname: 'api.omnimaas.com',
    path: '/v1/chat/completions',
    method: 'POST',
    headers: {
        'Content-Type': 'application/json',
        'Authorization': 'Bearer YOUR_API_KEY'
    }
};

const data = JSON.stringify({
    model: 'gpt-4',
    messages: [
        { role: 'user', content: '讲个笑话' }
    ],
    stream: true
});

const req = https.request(options, (res) => {
    res.on('data', (chunk) => {
        const lines = chunk.toString().split('\n');
        lines.forEach(line => {
            if (line.startsWith('data: ')) {
                const dataStr = line.slice(6);
                if (dataStr !== '[DONE]') {
                    try {
                        const json = JSON.parse(dataStr);
                        const content = json.choices[0].delta.content;
                        if (content) {
                            process.stdout.write(content);
                        }
                    } catch (e) {}
                }
            }
        });
    });
});

req.on('error', (error) => {
    console.error('请求失败:', error);
});

req.write(data);
req.end();
```
